{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"/home/thalusa/Documents/ResearchShare-v2/reactrs/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _objectSpread = require(\"/home/thalusa/Documents/ResearchShare-v2/reactrs/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread2\");\n\nvar _slicedToArray = require(\"/home/thalusa/Documents/ResearchShare-v2/reactrs/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/slicedToArray\");\n\nvar _awaitAsyncGenerator = require(\"/home/thalusa/Documents/ResearchShare-v2/reactrs/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\");\n\nvar _wrapAsyncGenerator = require(\"/home/thalusa/Documents/ResearchShare-v2/reactrs/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\");\n\nvar _asyncIterator = require(\"/home/thalusa/Documents/ResearchShare-v2/reactrs/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncIterator\");\n\nvar CID = require('cids');\n\nvar toCamel = require('./lib/object-to-camel');\n\nvar configure = require('./lib/configure');\n\nvar multipartRequest = require('./lib/multipart-request');\n\nvar toUrlSearchParams = require('./lib/to-url-search-params');\n\nvar _require = require('any-signal'),\n    anySignal = _require.anySignal;\n\nvar AbortController = require('native-abort-controller');\n\nmodule.exports = configure(function (api) {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/add-all/index')>}\n   */\n  function addAll(_x) {\n    return _addAll.apply(this, arguments);\n  }\n\n  function _addAll() {\n    _addAll = _wrapAsyncGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(source) {\n      var options,\n          controller,\n          signal,\n          _yield$_awaitAsyncGen,\n          headers,\n          body,\n          total,\n          parts,\n          _ref,\n          _ref2,\n          progressFn,\n          onUploadProgress,\n          res,\n          _iteratorNormalCompletion,\n          _didIteratorError,\n          _iteratorError,\n          _iterator,\n          _step,\n          _value,\n          file,\n          _args = arguments;\n\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              options = _args.length > 1 && _args[1] !== undefined ? _args[1] : {};\n              // allow aborting requests on body errors\n              controller = new AbortController();\n              signal = anySignal([controller.signal, options.signal]);\n              _context.next = 5;\n              return _awaitAsyncGenerator(multipartRequest(source, controller, options.headers));\n\n            case 5:\n              _yield$_awaitAsyncGen = _context.sent;\n              headers = _yield$_awaitAsyncGen.headers;\n              body = _yield$_awaitAsyncGen.body;\n              total = _yield$_awaitAsyncGen.total;\n              parts = _yield$_awaitAsyncGen.parts;\n              // In browser response body only starts streaming once upload is\n              // complete, at which point all the progress updates are invalid. If\n              // length of the content is computable we can interpret progress from\n              // `{ total, loaded}` passed to `onUploadProgress` and `multipart.total`\n              // in which case we disable progress updates to be written out.\n              _ref = typeof options.progress === 'function' ? createProgressHandler(total, parts, options.progress) : [null, null], _ref2 = _slicedToArray(_ref, 2), progressFn = _ref2[0], onUploadProgress = _ref2[1];\n              _context.next = 13;\n              return _awaitAsyncGenerator(api.post('add', {\n                searchParams: toUrlSearchParams(_objectSpread(_objectSpread({\n                  'stream-channels': true\n                }, options), {}, {\n                  progress: Boolean(progressFn)\n                })),\n                timeout: options.timeout,\n                onUploadProgress: onUploadProgress,\n                signal: signal,\n                headers: headers,\n                body: body\n              }));\n\n            case 13:\n              res = _context.sent;\n              _iteratorNormalCompletion = true;\n              _didIteratorError = false;\n              _context.prev = 16;\n              _iterator = _asyncIterator(res.ndjson());\n\n            case 18:\n              _context.next = 20;\n              return _awaitAsyncGenerator(_iterator.next());\n\n            case 20:\n              _step = _context.sent;\n              _iteratorNormalCompletion = _step.done;\n              _context.next = 24;\n              return _awaitAsyncGenerator(_step.value);\n\n            case 24:\n              _value = _context.sent;\n\n              if (_iteratorNormalCompletion) {\n                _context.next = 37;\n                break;\n              }\n\n              file = _value;\n              file = toCamel(file);\n\n              if (!(file.hash !== undefined)) {\n                _context.next = 33;\n                break;\n              }\n\n              _context.next = 31;\n              return toCoreInterface(file);\n\n            case 31:\n              _context.next = 34;\n              break;\n\n            case 33:\n              if (progressFn) {\n                progressFn(file.bytes || 0, file.name);\n              }\n\n            case 34:\n              _iteratorNormalCompletion = true;\n              _context.next = 18;\n              break;\n\n            case 37:\n              _context.next = 43;\n              break;\n\n            case 39:\n              _context.prev = 39;\n              _context.t0 = _context[\"catch\"](16);\n              _didIteratorError = true;\n              _iteratorError = _context.t0;\n\n            case 43:\n              _context.prev = 43;\n              _context.prev = 44;\n\n              if (!(!_iteratorNormalCompletion && _iterator.return != null)) {\n                _context.next = 48;\n                break;\n              }\n\n              _context.next = 48;\n              return _awaitAsyncGenerator(_iterator.return());\n\n            case 48:\n              _context.prev = 48;\n\n              if (!_didIteratorError) {\n                _context.next = 51;\n                break;\n              }\n\n              throw _iteratorError;\n\n            case 51:\n              return _context.finish(48);\n\n            case 52:\n              return _context.finish(43);\n\n            case 53:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee, null, [[16, 39, 43, 53], [44,, 48, 52]]);\n    }));\n    return _addAll.apply(this, arguments);\n  }\n\n  return addAll;\n});\n/**\n * Returns simple progress callback when content length isn't computable or a\n * progress event handler that calculates progress from upload progress events.\n *\n * @param {number} total\n * @param {{name:string, start:number, end:number}[]|null} parts\n * @param {(n:number, name:string) => void} progress\n */\n\nvar createProgressHandler = function createProgressHandler(total, parts, progress) {\n  return parts ? [null, createOnUploadPrgress(total, parts, progress)] : [progress, null];\n};\n/**\n * Creates a progress handler that interpolates progress from upload progress\n * events and total size of the content that is added.\n *\n * @param {number} size - actual content size\n * @param {{name:string, start:number, end:number}[]} parts\n * @param {(n:number, name:string) => void} progress\n * @returns {(event:{total:number, loaded: number}) => void}\n */\n\n\nvar createOnUploadPrgress = function createOnUploadPrgress(size, parts, progress) {\n  var index = 0;\n  var count = parts.length;\n  return function (_ref3) {\n    var loaded = _ref3.loaded,\n        total = _ref3.total;\n    // Derive position from the current progress.\n    var position = Math.floor(loaded / total * size);\n\n    while (index < count) {\n      var _parts$index = parts[index],\n          start = _parts$index.start,\n          end = _parts$index.end,\n          name = _parts$index.name; // If within current part range report progress and break the loop\n\n      if (position < end) {\n        progress(position - start, name);\n        break; // If passed current part range report final byte for the chunk and\n        // move to next one.\n      } else {\n        progress(end - start, name);\n        index += 1;\n      }\n    }\n  };\n};\n/**\n * @param {any} input\n * @returns {import('ipfs-core-types/src/files').UnixFSEntry}\n */\n\n\nfunction toCoreInterface(_ref4) {\n  var name = _ref4.name,\n      hash = _ref4.hash,\n      size = _ref4.size,\n      mode = _ref4.mode,\n      mtime = _ref4.mtime,\n      mtimeNsecs = _ref4.mtimeNsecs;\n  var output = {\n    path: name,\n    cid: new CID(hash),\n    size: parseInt(size)\n  };\n\n  if (mode != null) {\n    output.mode = parseInt(mode, 8);\n  }\n\n  if (mtime != null) {\n    output.mtime = {\n      secs: mtime,\n      nsecs: mtimeNsecs || 0\n    };\n  } // @ts-ignore\n\n\n  return output;\n}","map":{"version":3,"sources":["/home/thalusa/Documents/ResearchShare-v2/node_modules/ipfs-http-client/src/add-all.js"],"names":["CID","require","toCamel","configure","multipartRequest","toUrlSearchParams","anySignal","AbortController","module","exports","api","addAll","source","options","controller","signal","headers","body","total","parts","progress","createProgressHandler","progressFn","onUploadProgress","post","searchParams","Boolean","timeout","res","ndjson","file","hash","undefined","toCoreInterface","bytes","name","createOnUploadPrgress","size","index","count","length","loaded","position","Math","floor","start","end","mode","mtime","mtimeNsecs","output","path","cid","parseInt","secs","nsecs"],"mappings":"AAAA;;;;;;;;;;;;;;AAEA,IAAMA,GAAG,GAAGC,OAAO,CAAC,MAAD,CAAnB;;AACA,IAAMC,OAAO,GAAGD,OAAO,CAAC,uBAAD,CAAvB;;AACA,IAAME,SAAS,GAAGF,OAAO,CAAC,iBAAD,CAAzB;;AACA,IAAMG,gBAAgB,GAAGH,OAAO,CAAC,yBAAD,CAAhC;;AACA,IAAMI,iBAAiB,GAAGJ,OAAO,CAAC,4BAAD,CAAjC;;eACsBA,OAAO,CAAC,YAAD,C;IAArBK,S,YAAAA,S;;AACR,IAAMC,eAAe,GAAGN,OAAO,CAAC,yBAAD,CAA/B;;AAEAO,MAAM,CAACC,OAAP,GAAiBN,SAAS,CAAC,UAACO,GAAD,EAAS;AAClC;AACF;AACA;AAHoC,WAIjBC,MAJiB;AAAA;AAAA;;AAAA;AAAA,yEAIlC,iBAAyBC,MAAzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAiCC,cAAAA,OAAjC,2DAA2C,EAA3C;AACE;AACMC,cAAAA,UAFR,GAEqB,IAAIP,eAAJ,EAFrB;AAGQQ,cAAAA,MAHR,GAGiBT,SAAS,CAAC,CAACQ,UAAU,CAACC,MAAZ,EAAoBF,OAAO,CAACE,MAA5B,CAAD,CAH1B;AAAA;AAAA,0CAKUX,gBAAgB,CAACQ,MAAD,EAASE,UAAT,EAAqBD,OAAO,CAACG,OAA7B,CAL1B;;AAAA;AAAA;AAIUA,cAAAA,OAJV,yBAIUA,OAJV;AAImBC,cAAAA,IAJnB,yBAImBA,IAJnB;AAIyBC,cAAAA,KAJzB,yBAIyBA,KAJzB;AAIgCC,cAAAA,KAJhC,yBAIgCA,KAJhC;AAOE;AACA;AACA;AACA;AACA;AAXF,qBAYyC,OAAON,OAAO,CAACO,QAAf,KAA4B,UAA5B,GACnCC,qBAAqB,CAACH,KAAD,EAAQC,KAAR,EAAeN,OAAO,CAACO,QAAvB,CADc,GAEnC,CAAC,IAAD,EAAO,IAAP,CAdN,mCAYSE,UAZT,aAYqBC,gBAZrB;AAAA;AAAA,0CAgBoBb,GAAG,CAACc,IAAJ,CAAS,KAAT,EAAgB;AAChCC,gBAAAA,YAAY,EAAEpB,iBAAiB;AAC7B,qCAAmB;AADU,mBAE1BQ,OAF0B;AAG7BO,kBAAAA,QAAQ,EAAEM,OAAO,CAACJ,UAAD;AAHY,mBADC;AAMhCK,gBAAAA,OAAO,EAAEd,OAAO,CAACc,OANe;AAOhCJ,gBAAAA,gBAAgB,EAAhBA,gBAPgC;AAQhCR,gBAAAA,MAAM,EAANA,MARgC;AAShCC,gBAAAA,OAAO,EAAPA,OATgC;AAUhCC,gBAAAA,IAAI,EAAJA;AAVgC,eAAhB,CAhBpB;;AAAA;AAgBQW,cAAAA,GAhBR;AAAA;AAAA;AAAA;AAAA,yCA6ByBA,GAAG,CAACC,MAAJ,EA7BzB;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AA6BiBC,cAAAA,IA7BjB;AA8BIA,cAAAA,IAAI,GAAG5B,OAAO,CAAC4B,IAAD,CAAd;;AA9BJ,oBAgCQA,IAAI,CAACC,IAAL,KAAcC,SAhCtB;AAAA;AAAA;AAAA;;AAAA;AAiCM,qBAAMC,eAAe,CAACH,IAAD,CAArB;;AAjCN;AAAA;AAAA;;AAAA;AAkCW,kBAAIR,UAAJ,EAAgB;AACrBA,gBAAAA,UAAU,CAACQ,IAAI,CAACI,KAAL,IAAc,CAAf,EAAkBJ,IAAI,CAACK,IAAvB,CAAV;AACD;;AApCL;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAJkC;AAAA;AAAA;;AA2ClC,SAAOxB,MAAP;AACD,CA5CyB,CAA1B;AA8CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,IAAMU,qBAAqB,GAAG,SAAxBA,qBAAwB,CAACH,KAAD,EAAQC,KAAR,EAAeC,QAAf;AAAA,SAC5BD,KAAK,GAAG,CAAC,IAAD,EAAOiB,qBAAqB,CAAClB,KAAD,EAAQC,KAAR,EAAeC,QAAf,CAA5B,CAAH,GAA2D,CAACA,QAAD,EAAW,IAAX,CADpC;AAAA,CAA9B;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMgB,qBAAqB,GAAG,SAAxBA,qBAAwB,CAACC,IAAD,EAAOlB,KAAP,EAAcC,QAAd,EAA2B;AACvD,MAAIkB,KAAK,GAAG,CAAZ;AACA,MAAMC,KAAK,GAAGpB,KAAK,CAACqB,MAApB;AACA,SAAO,iBAAuB;AAAA,QAApBC,MAAoB,SAApBA,MAAoB;AAAA,QAAZvB,KAAY,SAAZA,KAAY;AAC5B;AACA,QAAMwB,QAAQ,GAAGC,IAAI,CAACC,KAAL,CAAWH,MAAM,GAAGvB,KAAT,GAAiBmB,IAA5B,CAAjB;;AACA,WAAOC,KAAK,GAAGC,KAAf,EAAsB;AAAA,yBACSpB,KAAK,CAACmB,KAAD,CADd;AAAA,UACZO,KADY,gBACZA,KADY;AAAA,UACLC,GADK,gBACLA,GADK;AAAA,UACAX,IADA,gBACAA,IADA,EAEpB;;AACA,UAAIO,QAAQ,GAAGI,GAAf,EAAoB;AAClB1B,QAAAA,QAAQ,CAACsB,QAAQ,GAAGG,KAAZ,EAAmBV,IAAnB,CAAR;AACA,cAFkB,CAGpB;AACA;AACC,OALD,MAKO;AACLf,QAAAA,QAAQ,CAAC0B,GAAG,GAAGD,KAAP,EAAcV,IAAd,CAAR;AACAG,QAAAA,KAAK,IAAI,CAAT;AACD;AACF;AACF,GAhBD;AAiBD,CApBD;AAsBA;AACA;AACA;AACA;;;AACA,SAASL,eAAT,QAAyE;AAAA,MAA7CE,IAA6C,SAA7CA,IAA6C;AAAA,MAAvCJ,IAAuC,SAAvCA,IAAuC;AAAA,MAAjCM,IAAiC,SAAjCA,IAAiC;AAAA,MAA3BU,IAA2B,SAA3BA,IAA2B;AAAA,MAArBC,KAAqB,SAArBA,KAAqB;AAAA,MAAdC,UAAc,SAAdA,UAAc;AACvE,MAAMC,MAAM,GAAG;AACbC,IAAAA,IAAI,EAAEhB,IADO;AAEbiB,IAAAA,GAAG,EAAE,IAAIpD,GAAJ,CAAQ+B,IAAR,CAFQ;AAGbM,IAAAA,IAAI,EAAEgB,QAAQ,CAAChB,IAAD;AAHD,GAAf;;AAMA,MAAIU,IAAI,IAAI,IAAZ,EAAkB;AAChBG,IAAAA,MAAM,CAACH,IAAP,GAAcM,QAAQ,CAACN,IAAD,EAAO,CAAP,CAAtB;AACD;;AAED,MAAIC,KAAK,IAAI,IAAb,EAAmB;AACjBE,IAAAA,MAAM,CAACF,KAAP,GAAe;AACbM,MAAAA,IAAI,EAAEN,KADO;AAEbO,MAAAA,KAAK,EAAEN,UAAU,IAAI;AAFR,KAAf;AAID,GAhBsE,CAkBvE;;;AACA,SAAOC,MAAP;AACD","sourcesContent":["'use strict'\n\nconst CID = require('cids')\nconst toCamel = require('./lib/object-to-camel')\nconst configure = require('./lib/configure')\nconst multipartRequest = require('./lib/multipart-request')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\nconst { anySignal } = require('any-signal')\nconst AbortController = require('native-abort-controller')\n\nmodule.exports = configure((api) => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/add-all/index')>}\n   */\n  async function * addAll (source, options = {}) {\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = anySignal([controller.signal, options.signal])\n    const { headers, body, total, parts } =\n      await multipartRequest(source, controller, options.headers)\n\n    // In browser response body only starts streaming once upload is\n    // complete, at which point all the progress updates are invalid. If\n    // length of the content is computable we can interpret progress from\n    // `{ total, loaded}` passed to `onUploadProgress` and `multipart.total`\n    // in which case we disable progress updates to be written out.\n    const [progressFn, onUploadProgress] = typeof options.progress === 'function'\n      ? createProgressHandler(total, parts, options.progress)\n      : [null, null]\n\n    const res = await api.post('add', {\n      searchParams: toUrlSearchParams({\n        'stream-channels': true,\n        ...options,\n        progress: Boolean(progressFn)\n      }),\n      timeout: options.timeout,\n      onUploadProgress,\n      signal,\n      headers,\n      body\n    })\n\n    for await (let file of res.ndjson()) {\n      file = toCamel(file)\n\n      if (file.hash !== undefined) {\n        yield toCoreInterface(file)\n      } else if (progressFn) {\n        progressFn(file.bytes || 0, file.name)\n      }\n    }\n  }\n  return addAll\n})\n\n/**\n * Returns simple progress callback when content length isn't computable or a\n * progress event handler that calculates progress from upload progress events.\n *\n * @param {number} total\n * @param {{name:string, start:number, end:number}[]|null} parts\n * @param {(n:number, name:string) => void} progress\n */\nconst createProgressHandler = (total, parts, progress) =>\n  parts ? [null, createOnUploadPrgress(total, parts, progress)] : [progress, null]\n\n/**\n * Creates a progress handler that interpolates progress from upload progress\n * events and total size of the content that is added.\n *\n * @param {number} size - actual content size\n * @param {{name:string, start:number, end:number}[]} parts\n * @param {(n:number, name:string) => void} progress\n * @returns {(event:{total:number, loaded: number}) => void}\n */\nconst createOnUploadPrgress = (size, parts, progress) => {\n  let index = 0\n  const count = parts.length\n  return ({ loaded, total }) => {\n    // Derive position from the current progress.\n    const position = Math.floor(loaded / total * size)\n    while (index < count) {\n      const { start, end, name } = parts[index]\n      // If within current part range report progress and break the loop\n      if (position < end) {\n        progress(position - start, name)\n        break\n      // If passed current part range report final byte for the chunk and\n      // move to next one.\n      } else {\n        progress(end - start, name)\n        index += 1\n      }\n    }\n  }\n}\n\n/**\n * @param {any} input\n * @returns {import('ipfs-core-types/src/files').UnixFSEntry}\n */\nfunction toCoreInterface ({ name, hash, size, mode, mtime, mtimeNsecs }) {\n  const output = {\n    path: name,\n    cid: new CID(hash),\n    size: parseInt(size)\n  }\n\n  if (mode != null) {\n    output.mode = parseInt(mode, 8)\n  }\n\n  if (mtime != null) {\n    output.mtime = {\n      secs: mtime,\n      nsecs: mtimeNsecs || 0\n    }\n  }\n\n  // @ts-ignore\n  return output\n}\n"]},"metadata":{},"sourceType":"script"}